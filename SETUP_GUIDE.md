# Neural Polygraph Setup Guide

This guide will help you get the repository up and running for your Medium article series.

## âœ… Repository Structure Created

The neural-polygraph repository has been initialized with the following structure:

```
neural-polygraph/
â”œâ”€â”€ README.md                          # Main repository documentation
â”œâ”€â”€ LICENSE                            # MIT License
â”œâ”€â”€ .gitignore                         # Git ignore rules
â”œâ”€â”€ pyproject.toml                     # Package configuration and dependencies
â”œâ”€â”€ SETUP_GUIDE.md                     # This file
â”‚
â”œâ”€â”€ tutorials/                         # Educational notebooks
â”‚   â”œâ”€â”€ README.md                      # Tutorial guide
â”‚   â”œâ”€â”€ 01_sae_basics.ipynb           # Introduction to SAEs
â”‚   â””â”€â”€ 02_feature_extraction.ipynb   # Feature comparison
â”‚
â”œâ”€â”€ experiments/                       # Research experiments
â”‚   â”œâ”€â”€ README.md                      # Experiment documentation
â”‚   â”œâ”€â”€ hallucination_biopsy.py       # Main experiment script
â”‚   â”œâ”€â”€ results/                      # Output directory
â”‚   â””â”€â”€ notebooks/                    # Analysis notebooks
â”‚
â””â”€â”€ src/hallucination_detector/       # Reusable package
    â”œâ”€â”€ __init__.py                    # Package exports
    â””â”€â”€ sae_utils.py                  # Core functions
```

## ğŸš€ Next Steps

### 1. Initialize Git Repository

```bash
cd /Users/ariahan/Documents/ai-research/neural-polygraph
git init
git add .
git commit -m "Initial repository structure for hallucination detection"
```

### 2. Create Virtual Environment

```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install Dependencies

```bash
# Install package in editable mode (includes all dependencies)
pip install -e .

# Or install with dev dependencies for development
pip install -e ".[dev]"
```

This will install all dependencies from `pyproject.toml`:
- `torch` - PyTorch for tensor operations
- `transformer-lens` - For model activation access
- `sae-lens` - For SAE loading and encoding
- `numpy` - Numerical operations
- `matplotlib`, `seaborn`, `plotly` - Visualization
- `scikit-learn`, `umap-learn` - Machine learning tools
- `jupyter`, `ipywidgets`, `notebook`, `jupyterlab` - Notebook interface

### 4. Test the Installation

```bash
# Test imports
python -c "from hallucination_detector import initialize_model_and_sae; print('âœ“ Package installed correctly')"
```

### 5. Run the Experiment

```bash
python experiments/hallucination_biopsy.py
```

**Note:** First run will download ~5GB of models. Subsequent runs use cached versions.

### 6. Launch Jupyter Notebooks

```bash
jupyter notebook tutorials/
```

Start with `01_sae_basics.ipynb` and work through sequentially.

## ğŸ“ Code Organization

### Core Functions (src/hallucination_detector/sae_utils.py)

The package provides these key functions:

1. **`initialize_model_and_sae(device=None)`**
   - Loads Gemma-2-2b and GemmaScope SAE
   - Auto-detects device (MPS/CUDA/CPU)
   - Returns: (model, sae, device)

2. **`extract_features(text, model, sae)`**
   - Extracts SAE feature activations from text
   - Returns: dict with indices, magnitudes, total_active, energy

3. **`decode_feature(feature_id, model, sae, top_k=5)`**
   - Translates feature to vocabulary words
   - Returns: dict with feature_id, words, logits

4. **`get_loudest_unique_features(fact_text, hall_text, model, sae, top_k=5)`**
   - Finds features unique to hallucination
   - Sorted by activation magnitude
   - Returns: list of feature indices

5. **`run_differential_diagnosis(fact_text, hall_text, model, sae)`**
   - Complete comparative analysis
   - Returns: dict with spectral_metrics, biomarkers, signatures

### Experiment Script (experiments/hallucination_biopsy.py)

Demonstrates the full methodology:
- Loads instruments
- Defines test case (fact vs hallucination)
- Runs differential diagnosis
- Identifies loudest unique features
- Decodes feature meanings
- Saves results to JSON

### Tutorial Notebooks

**01_sae_basics.ipynb:**
- Introduction to SAEs
- The "prism metaphor"
- Manual feature extraction
- Feature decoding

**02_feature_extraction.ipynb:**
- Using the hallucination_detector package
- Comparing multiple texts
- Finding unique features
- Differential diagnosis

## ğŸ¯ For Your Medium Articles

### Article 1: "The Prism Metaphor"
- Use: `tutorials/01_sae_basics.ipynb`
- Focus: What are SAEs, why they matter
- Code: Simple feature extraction examples
- Visuals: Feature activation patterns

### Article 2: "Spectral Signatures"
- Use: `tutorials/02_feature_extraction.ipynb`
- Focus: Comparing fact vs hallucination
- Code: Differential diagnosis methodology
- Visuals: Unique feature comparisons

### Article 3: "Hallucination Biomarkers"
- Use: `experiments/hallucination_biopsy.py`
- Focus: Experimental findings
- Code: Full experiment with results
- Visuals: Feature translations, energy differences

## ğŸ“Š Expected Results

Based on your experiments repo results:

```
Geography Teleportation:
  Unique features: 73
  Energy diff: +116.143
  Top feature: #9958 â†’ RB, RSD, RCS

Geography Teleportation 2:
  Unique features: 40
  Energy diff: -136.787
  Top feature: #10496 â†’ York, YORK, York
```

The simplified experiment in this repo uses a single example for clarity and speed.

## ğŸ”§ Customization

### Adding More Test Cases

Edit `experiments/hallucination_biopsy.py`:

```python
# Add more test cases in main()
test_cases = [
    {
        "fact": "Your factual statement",
        "hallucination": "Your hallucinated version"
    },
    # Add more...
]
```

### Using Different Models/SAEs

Edit `src/hallucination_detector/sae_utils.py`:

```python
# In initialize_model_and_sae()
model_name = "gemma-2-2b"  # Change model
sae_release = "gemma-scope-2b-pt-res-canonical"  # Change SAE
sae_id = "layer_5/width_16k/canonical"  # Change layer/width
```

## ğŸ› Troubleshooting

### Import Errors
```bash
# Make sure you're in the venv
source venv/bin/activate

# Reinstall in editable mode
pip install -e .
```

### Model Download Issues
```bash
# Check Hugging Face access
huggingface-cli whoami

# Login if needed
huggingface-cli login
```

### Memory Issues
- Close other applications
- Use CPU instead of GPU (automatic fallback)
- Reduce batch size (already minimal)

## ğŸ“š Resources

- **SAE Lens:** https://github.com/jbloomAus/SAELens
- **TransformerLens:** https://github.com/neelnanda-io/TransformerLens
- **Neuronpedia:** https://neuronpedia.org/gemma-2b
- **GemmaScope:** https://huggingface.co/google/gemma-scope

## âœ¨ Ready to Publish

The repository is now ready for:
- âœ… GitHub publication
- âœ… Medium article series
- âœ… Community experimentation
- âœ… Further research

## ğŸ“§ Next Actions

1. **Test the setup:**
   ```bash
   python experiments/hallucination_biopsy.py
   jupyter notebook tutorials/01_sae_basics.ipynb
   ```

2. **Create GitHub repo:**
   - Create new repo on GitHub
   - Add remote: `git remote add origin <url>`
   - Push: `git push -u origin main`

3. **Write Medium articles:**
   - Use notebooks as interactive examples
   - Reference experiment results
   - Link to GitHub repo

4. **Share with community:**
   - Post on Twitter/X
   - Share in ML/AI communities
   - Engage with feedback

---

**Good luck with your Medium article series!** ğŸš€

