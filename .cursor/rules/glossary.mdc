---
description: Domain Glossary: Hallucination Detection → Code Implementation
alwaysApply: false
---

# Domain Glossary: Hallucination Detection → Code Implementation

## Core Concepts

### Model → The LLM

**Code Mapping**:

- Variable: `model`, `llm`, `transformer`
- Type: `HookedTransformer` (from transformer_lens)
- Context: Language model being analyzed

**Usage**:

```python
from transformer_lens import HookedTransformer
model = HookedTransformer.from_pretrained("gemma-2-2b")
```

### SAE → Feature Analyzer

**Code Mapping**:

- Variable: `sae`, `autoencoder`
- Type: `SAE` (from sae_lens)
- Context: Sparse Autoencoder for feature extraction

**Usage**:

```python
from sae_lens import SAE
sae = SAE.from_pretrained(
    release="gemma-scope-2b-pt-res-canonical",
    sae_id="layer_5/width_16k/canonical"
)
```

### Features → SAE Activations

**Code Mapping**:

- Variable: `features`, `activations`, `feature_indices`
- Type: `torch.Tensor` or `List[int]`
- Context: Sparse feature activations from SAE

**Usage**:

```python
features = extract_features(text, model, sae)
top_features = features['top_features']  # Indices of activated features
```

### Unique Features → Hallucination Biomarkers

**Code Mapping**:

- Variable: `unique_features`, `biomarkers`, `hallucination_signatures`
- Type: `List[int]` (feature indices)
- Context: Features present in hallucination but not in fact

**Usage**:

```python
unique_features = get_loudest_unique_features(
    fact_text, 
    hallucination_text, 
    model, 
    sae
)
```

### Feature Decoding → Interpretability

**Code Mapping**:

- Variable: `decoded`, `interpretation`, `feature_meaning`
- Type: `Dict` with keys: `words`, `top_tokens`, `activation`
- Context: Semantic meaning of a feature

**Usage**:

```python
decoded = decode_feature(feature_id, model, sae)
print(f"Feature #{feature_id} → {decoded['words']}")
```

### Energy Patterns → Activation Magnitudes

**Code Mapping**:

- Variable: `energy`, `activation_magnitude`, `intensity`
- Type: `float` or `torch.Tensor`
- Context: Strength of feature activation

**Usage**:

```python
fact_energy = calculate_feature_energy(fact_features)
hallucination_energy = calculate_feature_energy(hallucination_features)
energy_difference = hallucination_energy - fact_energy
```

## Hallucination Types

### Geography Errors

**Pattern**: Wrong location information
**Signature**: Location-specific features activate
**Example**: "Eiffel Tower in Rome" → activates location features for wrong cities

### Temporal Errors

**Pattern**: Wrong time/era information
**Signature**: Time-specific features activate
**Example**: "Shakespeare wrote in 1800s" → activates wrong era features

### Biological Errors

**Pattern**: Wrong biological facts
**Signature**: Anatomy/capability features activate
**Example**: "Humans have 3 hearts" → activates wrong anatomy features

## Analysis Methods

### Feature Comparison

**Purpose**: Identify differences between fact and hallucination
**Method**: Compare feature sets, find unique activations
**Output**: List of unique feature indices

### Biomarker Identification

**Purpose**: Find interpretable hallucination signatures
**Method**: Decode unique features to semantic meaning
**Output**: Dictionary mapping features to decoded meanings

### Pattern Analysis

**Purpose**: Identify consistent hallucination patterns
**Method**: Analyze multiple examples, find common features
**Output**: Statistical patterns and common biomarkers

○reference|philosophy:philosophy.mdc|global:global.mdc|physics:physics.mdc
